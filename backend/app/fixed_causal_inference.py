"""
ä¿®å¤ç‰ˆ UMe èŒ¶é¥®é”€å”®æ•°æ®å› æœæ¨æ–­åˆ†æå¼•æ“ - å¢å¼ºç‰ˆ
åŒ…å«é”€å”®é¢„æµ‹ã€å®¢æˆ·åˆ†æã€ä¿ƒé”€åˆ†æç­‰åŠŸèƒ½
"""

import pandas as pd
import numpy as np

pd.options.display.max_columns = None

from datetime import timedelta
import clickhouse_connect
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
import warnings;

warnings.filterwarnings("ignore")

# EconMLï¼ˆå¼‚è´¨æ•ˆåº”åˆ†æï¼‰
from econml.dml import LinearDML

# å¤©æ°”å’ŒèŠ‚å‡æ—¥
import requests
import holidays

# é¢„æµ‹æ¨¡å‹
try:
    from prophet import Prophet
    HAS_PROPHET = True

except ImportError:
    print("âš ï¸ Prophetæœªå®‰è£…ï¼Œé¢„æµ‹åŠŸèƒ½å°†ä½¿ç”¨ç®€å•æ¨¡å‹")
    HAS_PROPHET = False

# æ•°æ®ç±»å‹å¤„ç†
from typing import Dict, List, Any, Optional, Tuple
import decimal

# å¯è§†åŒ–
import plotly.graph_objects as go
import plotly.express as px
import plotly.io as pio
from plotly.subplots import make_subplots

pio.renderers.default = "browser"


class UMeCausalInferenceEngine:
    """UMe èŒ¶é¥®å› æœæ¨æ–­åˆ†æå¼•æ“ - å¢å¼ºç‰ˆ"""

    def __init__(self, ch_config: dict, weather_api_key: str = None):
        self.ch_client = clickhouse_connect.get_client(**ch_config)
        self.scaler = StandardScaler()
        self.weather_api_key = weather_api_key

        # ç¾å›½èŠ‚å‡æ—¥
        self.us_holidays = holidays.US()

        # åˆ†æç»“æœå­˜å‚¨
        self.analysis_results = {}
        self.raw_data = None
        self.enhanced_data = None
        self.customer_data = None
        self.promotion_data = None
        self.forecast_results = None

    # ============================================================
    # 1. æ•°æ®æŠ½å–ï¼ˆå¢å¼ºç‰ˆï¼‰
    # ============================================================
    def load_integrated_data(self, start_date: str, end_date: str) -> pd.DataFrame:
        """æ‹‰å–é”€å”®æ•°æ®å¹¶ä¿®å¤èšåˆé—®é¢˜"""
        print("ğŸ“Š æ­£åœ¨åŠ è½½é”€å”®æ•°æ®...")

        # ä¿®å¤ï¼šé¿å…any()èšåˆå‡½æ•°çš„åµŒå¥—é—®é¢˜ï¼Œä½¿ç”¨å­æŸ¥è¯¢æ–¹å¼
        sales_query = f"""
        WITH daily_base AS (
            SELECT
                toDate(created_at_pt) AS date,
                location_id,
                location_name,
                substring(location_name, position(location_name,'-')+1, 2) AS state,
                toDayOfWeek(created_at_pt) AS day_of_week,
                order_id,
                item_total_amt,
                item_discount,
                customer_id,
                is_loyalty,
                campaign_names,
                category_name,
                item_name,
                toHour(created_at_pt) AS hour_of_day
            FROM dw.fact_order_item_variations
            WHERE
                created_at_pt >= '{start_date}'
                AND created_at_pt <= '{end_date}'
                AND pay_status = 'COMPLETED'
        )
        SELECT
            date,
            location_id,
            any(location_name) AS location_name,
            any(state) AS state,
            any(day_of_week) AS day_of_week,

            /* æ ¸å¿ƒæŒ‡æ ‡ */
            countDistinct(order_id) AS order_count,
            sum(item_total_amt) AS total_revenue,
            avg(item_total_amt) AS avg_order_value,
            sum(item_discount) AS total_discount,
            sum(item_discount>0) AS discount_orders,
            countDistinct(customer_id) AS unique_customers,
            sum(is_loyalty) AS loyalty_orders,
            sum(arrayExists(x->x='BOGO', assumeNotNull(campaign_names))) AS bogo_orders,
            countDistinct(category_name) AS category_diversity,

            /* æ—¶æ®µåˆ†å¸ƒ */
            sum(if(hour_of_day BETWEEN 7 AND 10, 1, 0)) AS morning_orders,
            sum(if(hour_of_day BETWEEN 11 AND 14, 1, 0)) AS lunch_orders,
            sum(if(hour_of_day BETWEEN 15 AND 17, 1, 0)) AS afternoon_orders,
            sum(if(hour_of_day BETWEEN 18 AND 21, 1, 0)) AS evening_orders,

            /* æŒ‰ç±»åˆ«ç»Ÿè®¡ - åŸºäºå®é™…category_name */
            sum(if(category_name IN ('Milk Tea', 'Fruit Tea', 'Slush', 'Seasonal Drinks'), 1, 0)) AS tea_drinks_orders,
            sum(if(category_name = 'Coffee', 1, 0)) AS coffee_orders,
            sum(if(category_name IN ('Snacks', 'Toast', 'Mochi Donut'), 1, 0)) AS food_orders,
            sum(if(category_name = 'Caffeine-Free Drinks', 1, 0)) AS caffeine_free_orders,
            sum(if(category_name = 'Try Our New', 1, 0)) AS new_product_orders

        FROM daily_base
        GROUP BY
            date, location_id
        ORDER BY
            date, location_id
        """

        sales_df = self.ch_client.query_df(sales_query)

        # ä¿®å¤ï¼šç«‹å³è½¬æ¢æ•°å€¼ç±»å‹
        numeric_cols = [
            'order_count', 'total_revenue', 'avg_order_value', 'total_discount',
            'discount_orders', 'unique_customers', 'loyalty_orders', 'bogo_orders',
            'category_diversity', 'morning_orders', 'lunch_orders', 'afternoon_orders',
            'evening_orders', 'tea_drinks_orders', 'coffee_orders', 'food_orders',
            'caffeine_free_orders', 'new_product_orders', 'day_of_week'
        ]

        for col in numeric_cols:
            if col in sales_df.columns:
                sales_df[col] = pd.to_numeric(sales_df[col], errors='coerce')

        print(f"âœ… åŠ è½½ {len(sales_df)} æ¡é”€å”®æ•°æ®")
        self.raw_data = sales_df.copy()
        return sales_df.fillna(0)

    def load_customer_profile_data(self, start_date: str, end_date: str) -> pd.DataFrame:
        """åŠ è½½å®¢æˆ·ç”»åƒæ•°æ®"""
        print("ğŸ‘¥ æ­£åœ¨åŠ è½½å®¢æˆ·ç”»åƒæ•°æ®...")

        customer_query = f"""
        SELECT
            customer_id,
            given_name,
            family_name,
            phone_number,
            birthday,
            creation_source,
            location_id,
            location_name,
            customer_created_date,
            loyalty_created_date,
            order_final_total_cnt AS total_orders,
            order_final_total_amt AS total_spent,
            order_final_avg_amt AS avg_order_value,
            order_first_date AS first_order_date,
            order_last_date AS last_order_date,

            /* å®¢æˆ·åˆ†ç±»æ ‡ç­¾ */
            offline,
            dormant,
            ultra_low_frequency,
            hardcore,
            silent,
            loyal,
            regular,
            potential,
            high_spending,
            medium_spending,
            low_spending,
            highly_active,
            moderately_active,
            low_active,
            churned,
            high_value_customer,
            high_potential_customer,
            key_development_customer,
            regular_customer,
            critical_win_back_customer,
            general_value_customer,
            general_win_back_customer,
            inactive_customer,

            /* æ ‡ç­¾æ•°ç»„ */
            rfm_labels,
            loyalty_labels,
            consumption_labels

        FROM ads.customer_profile
        WHERE
            order_last_date >= '{start_date}'
            OR customer_created_date >= '{start_date}'
        """

        try:
            customer_df = self.ch_client.query_df(customer_query)
            print(f"âœ… åŠ è½½ {len(customer_df)} æ¡å®¢æˆ·æ•°æ®")
            self.customer_data = customer_df
            return customer_df
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å®¢æˆ·æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()

    def load_promotion_sales_data(self, start_date: str, end_date: str) -> pd.DataFrame:
        """åŠ è½½ä¿ƒé”€é”€å”®æ•°æ®"""
        print("ğŸ¯ æ­£åœ¨åŠ è½½ä¿ƒé”€æ•°æ®...")

        promotion_query = f"""
        SELECT
            order_date,
            weekdays,
            location_id,
            location_name,
            item_name,
            category_name,
            source,
            source_type,
            item_amt,
            item_total_amt,
            item_qty,
            order_qty,
            order_amt,
            milk_amt,
            milk_item_qty,
            non_milk_amt,
            non_milk_item_qty
        FROM ads.promotion_sales
        WHERE
            order_date >= '{start_date}'
            AND order_date <= '{end_date}'
        """

        try:
            promotion_df = self.ch_client.query_df(promotion_query)
            print(f"âœ… åŠ è½½ {len(promotion_df)} æ¡ä¿ƒé”€æ•°æ®")
            self.promotion_data = promotion_df
            return promotion_df
        except Exception as e:
            print(f"âš ï¸ åŠ è½½ä¿ƒé”€æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()

    # ============================================================
    # 2. å¤©æ°”æ•°æ®è·å–
    # ============================================================
    def get_weather_data(self, start_date: str, end_date: str, locations_df: pd.DataFrame) -> pd.DataFrame:
        """è·å–å¤©æ°”æ•°æ®"""
        print("ğŸŒ¤ï¸ æ­£åœ¨è·å–å¤©æ°”æ•°æ®...")

        # å·åæ ‡æ˜ å°„
        state_coords = {
            'CA': {'lat': 37.7749, 'lon': -122.4194, 'city': 'San Francisco'},
            'IL': {'lat': 41.8781, 'lon': -87.6298, 'city': 'Chicago'},
            'AZ': {'lat': 33.4484, 'lon': -112.0740, 'city': 'Phoenix'},
            'TX': {'lat': 29.7604, 'lon': -95.3698, 'city': 'Houston'},
        }

        unique_states = locations_df['state'].unique()
        weather_data_list = []

        for state in unique_states:
            if state not in state_coords:
                continue

            coords = state_coords[state]
            weather_data = self._fetch_weather_api(
                start_date, end_date, coords['lat'], coords['lon'], state
            )

            if weather_data is not None:
                weather_data_list.append(weather_data)

        if weather_data_list:
            weather_df = pd.concat(weather_data_list, ignore_index=True)
            print(f"âœ… è·å– {len(weather_df)} æ¡å¤©æ°”è®°å½•")
        else:
            print("âš ï¸ ä½¿ç”¨æ¨¡æ‹Ÿå¤©æ°”æ•°æ®")
            weather_df = self._generate_mock_weather_data(start_date, end_date, unique_states)

        return weather_df

    def _fetch_weather_api(self, start_date: str, end_date: str, lat: float, lon: float, state: str) -> pd.DataFrame:
        """ä»Open-Meteo APIè·å–å¤©æ°”æ•°æ®"""
        try:
            url = "https://archive-api.open-meteo.com/v1/archive"
            params = {
                'latitude': lat,
                'longitude': lon,
                'start_date': start_date,
                'end_date': end_date,
                'daily': [
                    'temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean',
                    'precipitation_sum', 'rain_sum', 'snowfall_sum',
                    'windspeed_10m_max', 'sunshine_duration'
                ],
                'timezone': 'America/Los_Angeles'
            }

            response = requests.get(url, params=params, timeout=30)

            if response.status_code == 200:
                data = response.json()
                weather_df = pd.DataFrame({
                    'date': pd.to_datetime(data['daily']['time']),
                    'state': state,
                    'temperature_max': data['daily']['temperature_2m_max'],
                    'temperature_min': data['daily']['temperature_2m_min'],
                    'temperature_mean': data['daily']['temperature_2m_mean'],
                    'precipitation': data['daily']['precipitation_sum'],
                    'rain': data['daily']['rain_sum'],
                    'snow': data['daily']['snowfall_sum'],
                    'wind_speed': data['daily']['windspeed_10m_max'],
                    'sunshine_hours': data['daily']['sunshine_duration']
                })
                return weather_df
            else:
                return None

        except Exception as e:
            print(f"å¤©æ°”APIè¯·æ±‚å¤±è´¥: {e}")
            return None

    def _generate_mock_weather_data(self, start_date: str, end_date: str, states: list) -> pd.DataFrame:
        """ç”Ÿæˆæ¨¡æ‹Ÿå¤©æ°”æ•°æ®"""
        date_range = pd.date_range(start=start_date, end=end_date, freq='D')
        weather_data = []

        for state in states:
            base_temp = {'CA': 22, 'IL': 15, 'AZ': 30, 'TX': 25}.get(state, 20)

            for date in date_range:
                day_of_year = date.timetuple().tm_yday
                seasonal_factor = np.sin(2 * np.pi * day_of_year / 365.25)

                temp_max = base_temp + 8 * seasonal_factor + np.random.normal(0, 3)
                temp_min = temp_max - np.random.uniform(5, 15)
                temp_mean = (temp_max + temp_min) / 2

                weather_data.append({
                    'date': date,
                    'state': state,
                    'temperature_max': temp_max,
                    'temperature_min': temp_min,
                    'temperature_mean': temp_mean,
                    'precipitation': max(0, np.random.exponential(2) - 1),
                    'rain': max(0, np.random.exponential(1.5) - 0.5),
                    'snow': 0 if state in ['CA', 'AZ', 'TX'] else max(0, np.random.exponential(0.5) - 2),
                    'wind_speed': np.random.uniform(5, 25),
                    'sunshine_hours': np.random.uniform(4, 12)
                })

        return pd.DataFrame(weather_data)

    # ============================================================
    # 3. ç‰¹å¾å·¥ç¨‹ï¼ˆé›†æˆç‰ˆï¼‰
    # ============================================================
    def create_all_features(self, sales_df: pd.DataFrame, weather_df: pd.DataFrame = None) -> pd.DataFrame:
        """åˆ›å»ºæ‰€æœ‰ç‰¹å¾ï¼šä¿ƒé”€ã€å¤©æ°”ã€èŠ‚å‡æ—¥ã€æ—¶é—´"""
        print("ğŸ”§ æ­£åœ¨åˆ›å»ºç‰¹å¾...")

        df = sales_df.copy()
        df['date'] = pd.to_datetime(df['date'])

        # 1. åŸºç¡€ä¿ƒé”€ç‰¹å¾
        df = self._create_promotion_features(df)

        # 2. æ—¶é—´å’ŒèŠ‚å‡æ—¥ç‰¹å¾
        df = self._create_calendar_features(df)

        # 3. å¤©æ°”ç‰¹å¾ï¼ˆå¦‚æœæœ‰æ•°æ®ï¼‰
        if weather_df is not None:
            df = self._create_weather_features(df, weather_df)

        # 4. äº¤äº’ç‰¹å¾
        df = self._create_interaction_features(df)

        # 5. å®¢æˆ·ç‰¹å¾ï¼ˆå¦‚æœæœ‰æ•°æ®ï¼‰
        if self.customer_data is not None:
            df = self._create_customer_features(df)

        print(f"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆï¼Œå…± {len(df.columns)} ä¸ªç‰¹å¾")
        self.enhanced_data = df.copy()
        return df

    def _create_promotion_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """åˆ›å»ºä¿ƒé”€ç›¸å…³ç‰¹å¾"""
        # ç¡®ä¿æ•°å€¼ç±»å‹
        numeric_cols = ['total_revenue', 'total_discount', 'bogo_orders']
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')

        df['has_promotion'] = (df['total_discount'] > 0).astype(int)
        df['promotion_intensity'] = df['total_discount'] / (df['total_revenue'] + df['total_discount'] + 1e-3)
        df['has_bogo'] = (df['bogo_orders'] > 0).astype(int)

        # ä¿®å¤ï¼šå®‰å…¨çš„åˆ†ä½æ•°è®¡ç®—
        try:
            df['total_revenue'] = df['total_revenue'].astype(float)
            df['low_performance'] = df.groupby('location_id')['total_revenue'].transform(
                lambda x: (x < x.quantile(0.25)).astype(int)
            )
        except Exception as e:
            print(f"åˆ†ä½æ•°è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
            df['low_performance'] = 0

        return df

    def _create_calendar_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """åˆ›å»ºæ—¥å†å’ŒèŠ‚å‡æ—¥ç‰¹å¾"""
        df['is_weekend'] = df['date'].dt.dayofweek.isin([5, 6]).astype(int)
        df['is_monday'] = (df['date'].dt.dayofweek == 0).astype(int)
        df['is_friday'] = (df['date'].dt.dayofweek == 4).astype(int)
        df['is_member_day'] = (df['date'].dt.dayofweek == 2).astype(int)  # å‘¨ä¸‰

        # èŠ‚å‡æ—¥ç‰¹å¾
        df['is_holiday'] = df['date'].apply(lambda x: x.date() in self.us_holidays).astype(int)
        df['is_holiday_week'] = df['date'].apply(
            lambda x: any((x + timedelta(days=i)).date() in self.us_holidays for i in range(-3, 4))
        ).astype(int)

        # å­£èŠ‚ç‰¹å¾
        df['is_summer'] = df['date'].dt.month.isin([6, 7, 8]).astype(int)
        df['is_winter'] = df['date'].dt.month.isin([12, 1, 2]).astype(int)
        df['is_spring'] = df['date'].dt.month.isin([3, 4, 5]).astype(int)
        df['is_fall'] = df['date'].dt.month.isin([9, 10, 11]).astype(int)

        # ç‰¹æ®ŠèŠ‚æ—¥
        df['is_valentine'] = ((df['date'].dt.month == 2) & (df['date'].dt.day == 14)).astype(int)
        df['is_christmas_season'] = ((df['date'].dt.month == 12) & (df['date'].dt.day >= 15)).astype(int)

        return df

    def _create_weather_features(self, df: pd.DataFrame, weather_df: pd.DataFrame) -> pd.DataFrame:
        """åˆ›å»ºå¤©æ°”ç‰¹å¾"""
        if weather_df is None or len(weather_df) == 0:
            return df

        # ç¡®ä¿æ—¥æœŸç±»å‹ä¸€è‡´
        weather_df['date'] = pd.to_datetime(weather_df['date'])

        # ç¡®ä¿å¤©æ°”æ•°æ®æ•°å€¼ç±»å‹
        weather_numeric_cols = [
            'temperature_max', 'temperature_min', 'temperature_mean',
            'precipitation', 'rain', 'snow', 'wind_speed', 'sunshine_hours'
        ]
        for col in weather_numeric_cols:
            if col in weather_df.columns:
                weather_df[col] = pd.to_numeric(weather_df[col], errors='coerce')

        # åˆå¹¶å¤©æ°”æ•°æ®
        merged = df.merge(weather_df, on=['date', 'state'], how='left')
        merged = merged.fillna(method='ffill').fillna(method='bfill')

        # å¤©æ°”åˆ†ç±»ç‰¹å¾
        merged['is_hot'] = (merged['temperature_max'] > 30).astype(int)
        merged['is_cold'] = (merged['temperature_max'] < 10).astype(int)
        merged['is_mild'] = ((merged['temperature_max'] >= 15) & (merged['temperature_max'] <= 25)).astype(int)

        merged['is_rainy'] = (merged['precipitation'] > 2).astype(int)
        merged['is_heavy_rain'] = (merged['precipitation'] > 10).astype(int)
        merged['is_snowy'] = (merged['snow'] > 0).astype(int)

        merged['is_sunny'] = (merged['sunshine_hours'] > 8).astype(int)
        merged['is_windy'] = (merged['wind_speed'] > 20).astype(int)

        # èˆ’é€‚åº¦æŒ‡æ•°
        merged['comfort_index'] = (
                (merged['temperature_mean'] - 20).abs() * (-0.1) +
                merged['sunshine_hours'] * 0.1 -
                merged['precipitation'] * 0.05 -
                merged['wind_speed'] * 0.02
        )

        return merged.fillna(0)

    def _create_interaction_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """åˆ›å»ºäº¤äº’ç‰¹å¾"""
        # åŸºç¡€äº¤äº’
        df['weekend_promotion'] = df['is_weekend'] * df['has_promotion']
        df['holiday_promotion'] = df['is_holiday'] * df['has_promotion']

        # å¤©æ°”äº¤äº’ï¼ˆå¦‚æœæœ‰å¤©æ°”æ•°æ®ï¼‰
        if 'is_rainy' in df.columns:
            df['rainy_promotion'] = df['is_rainy'] * df['has_promotion']
        if 'is_hot' in df.columns:
            df['hot_promotion'] = df['is_hot'] * df['has_promotion']

        return df

    def _create_customer_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """åˆ›å»ºå®¢æˆ·ç‰¹å¾"""
        if self.customer_data is None:
            return df

        # æŒ‰location_idèšåˆå®¢æˆ·ç‰¹å¾
        customer_summary = self.customer_data.groupby('location_id').agg({
            'high_value_customer': 'sum',
            'loyal': 'sum',
            'churned': 'sum',
            'total_spent': 'mean',
            'avg_order_value': 'mean'
        }).reset_index()

        customer_summary.columns = [
            'location_id',
            'high_value_customers',
            'loyal_customers',
            'churned_customers',
            'avg_customer_spent',
            'avg_customer_order_value'
        ]

        # åˆå¹¶åˆ°ä¸»æ•°æ®
        df = df.merge(customer_summary, on='location_id', how='left')

        return df.fillna(0)

    # ============================================================
    # 4. é”€å”®é¢„æµ‹åŠŸèƒ½ï¼ˆæ–°å¢ï¼‰
    # ============================================================
    def create_sales_forecast(self, days_ahead: int = 7) -> Dict[str, Any]:
        """åˆ›å»ºé”€å”®é¢„æµ‹"""
        print(f"\nğŸ”® å¼€å§‹åˆ›å»º {days_ahead} å¤©é”€å”®é¢„æµ‹...")

        if self.enhanced_data is None:
            print("âŒ è¯·å…ˆè¿è¡Œå®Œæ•´åˆ†æä»¥è·å–æ•°æ®")
            return {}

        # å‡†å¤‡æ•°æ®
        enhanced_data = self.enhanced_data.copy()
        enhanced_data['date'] = pd.to_datetime(enhanced_data['date'])

        # æŒ‰æ—¥æœŸèšåˆ
        daily_revenue = enhanced_data.groupby('date')['total_revenue'].sum().reset_index()
        daily_revenue.columns = ['ds', 'y']

        # æ£€æŸ¥æ•°æ®é‡
        if len(daily_revenue) < 30:
            print(f"âš ï¸ é¢„æµ‹éœ€è¦è‡³å°‘30å¤©çš„å†å²æ•°æ®ï¼Œå½“å‰åªæœ‰{len(daily_revenue)}å¤©")
            return {
                'error': 'æ•°æ®ä¸è¶³',
                'required_days': 30,
                'current_days': len(daily_revenue)
            }

        try:
            if HAS_PROPHET:
                # ä½¿ç”¨Prophetæ¨¡å‹
                forecast_result = self._prophet_forecast(daily_revenue, days_ahead)
            else:
                # ä½¿ç”¨ç®€å•æ¨¡å‹
                forecast_result = self._simple_forecast(daily_revenue, days_ahead)

            # å­˜å‚¨é¢„æµ‹ç»“æœ
            self.forecast_results = forecast_result

            # åˆ›å»ºé¢„æµ‹æ‘˜è¦
            forecast_summary = self._create_forecast_summary(forecast_result)

            print(f"âœ… é¢„æµ‹å®Œæˆï¼Œæœªæ¥{days_ahead}å¤©é¢„æµ‹æ€»é¢: ${forecast_summary['total_forecast']:,.0f}")

            return {
                'forecast': forecast_result,
                'summary': forecast_summary,
                'method': 'Prophet' if HAS_PROPHET else 'Polynomial Regression'
            }

        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            return {'error': str(e)}

    def _prophet_forecast(self, daily_revenue: pd.DataFrame, days_ahead: int) -> pd.DataFrame:
        """ä½¿ç”¨Prophetè¿›è¡Œé¢„æµ‹"""
        # åˆå§‹åŒ–æ¨¡å‹
        model = Prophet(
            daily_seasonality=True,
            weekly_seasonality=True,
            yearly_seasonality=False,
            changepoint_prior_scale=0.05
        )

        # æ·»åŠ èŠ‚å‡æ—¥ï¼ˆå¦‚æœæœ‰ï¼‰
        if 'is_holiday' in self.enhanced_data.columns:
            holidays = self.enhanced_data[self.enhanced_data['is_holiday'] == 1][['date']].copy()
            holidays.columns = ['ds']
            holidays['holiday'] = 'US_holiday'
            holidays = holidays.drop_duplicates()
            model = Prophet(
                daily_seasonality=True,
                weekly_seasonality=True,
                yearly_seasonality=False,
                changepoint_prior_scale=0.05,
                holidays=holidays
            )

        # è®­ç»ƒæ¨¡å‹
        model.fit(daily_revenue)

        # åˆ›å»ºé¢„æµ‹æ•°æ®æ¡†
        future = model.make_future_dataframe(periods=days_ahead)

        # è¿›è¡Œé¢„æµ‹
        forecast = model.predict(future)

        # åˆ†ç¦»å†å²å’Œæœªæ¥
        last_date = daily_revenue['ds'].max()
        future_forecast = forecast[forecast['ds'] > last_date].copy()

        # æ·»åŠ å®é™…å€¼åˆ°å†å²éƒ¨åˆ†
        forecast = forecast.merge(daily_revenue, on='ds', how='left')

        return forecast

    def _simple_forecast(self, daily_revenue: pd.DataFrame, days_ahead: int) -> pd.DataFrame:
        """ä½¿ç”¨ç®€å•æ¨¡å‹è¿›è¡Œé¢„æµ‹"""
        from sklearn.linear_model import LinearRegression
        from sklearn.preprocessing import PolynomialFeatures

        # å‡†å¤‡ç‰¹å¾
        daily_revenue['day_of_week'] = daily_revenue['ds'].dt.dayofweek
        daily_revenue['day_of_month'] = daily_revenue['ds'].dt.day
        daily_revenue['days_since_start'] = (daily_revenue['ds'] - daily_revenue['ds'].min()).dt.days

        # ç‰¹å¾åˆ—è¡¨
        features = ['days_since_start', 'day_of_week', 'day_of_month']
        X = daily_revenue[features]
        y = daily_revenue['y']

        # å¤šé¡¹å¼ç‰¹å¾
        poly = PolynomialFeatures(degree=2, include_bias=False)
        X_poly = poly.fit_transform(X)

        # è®­ç»ƒæ¨¡å‹
        model = LinearRegression()
        model.fit(X_poly, y)

        # åˆ›å»ºæœªæ¥æ—¥æœŸ
        last_date = daily_revenue['ds'].max()
        future_dates = pd.date_range(
            start=last_date + timedelta(days=1),
            periods=days_ahead
        )

        # åˆ›å»ºæœªæ¥ç‰¹å¾
        future_data = pd.DataFrame({
            'ds': future_dates,
            'day_of_week': future_dates.dayofweek,
            'day_of_month': future_dates.day,
            'days_since_start': (future_dates - daily_revenue['ds'].min()).days
        })

        X_future = future_data[features]
        X_future_poly = poly.transform(X_future)

        # é¢„æµ‹
        predictions = model.predict(X_future_poly)

        # è®¡ç®—ç½®ä¿¡åŒºé—´
        std_error = np.std(y - model.predict(X_poly))

        # ç»„åˆç»“æœ
        forecast = pd.DataFrame({
            'ds': pd.concat([daily_revenue['ds'], future_dates]),
            'yhat': np.concatenate([model.predict(X_poly), predictions]),
            'yhat_lower': np.concatenate([
                model.predict(X_poly) - 1.96 * std_error,
                predictions - 1.96 * std_error
            ]),
            'yhat_upper': np.concatenate([
                model.predict(X_poly) + 1.96 * std_error,
                predictions + 1.96 * std_error
            ])
        })

        # æ·»åŠ å®é™…å€¼
        forecast = forecast.merge(daily_revenue[['ds', 'y']], on='ds', how='left')

        return forecast

    def _create_forecast_summary(self, forecast: pd.DataFrame) -> Dict[str, Any]:
        """åˆ›å»ºé¢„æµ‹æ‘˜è¦"""
        # è·å–æœªæ¥é¢„æµ‹
        last_actual_date = forecast[forecast['y'].notna()]['ds'].max()
        future_forecast = forecast[forecast['ds'] > last_actual_date]

        # è®¡ç®—ç»Ÿè®¡
        total_forecast = future_forecast['yhat'].sum()
        avg_forecast = future_forecast['yhat'].mean()
        max_forecast = future_forecast['yhat'].max()
        min_forecast = future_forecast['yhat'].min()

        # è¯†åˆ«é£é™©
        low_inventory_risk = []  # é¢„ç•™æ¥å£

        return {
            'total_forecast': total_forecast,
            'avg_daily_forecast': avg_forecast,
            'max_daily_forecast': max_forecast,
            'min_daily_forecast': min_forecast,
            'forecast_days': len(future_forecast),
            'low_inventory_risk': low_inventory_risk,
            'last_actual_date': last_actual_date.strftime('%Y-%m-%d'),
            'forecast_start_date': future_forecast['ds'].min().strftime('%Y-%m-%d'),
            'forecast_end_date': future_forecast['ds'].max().strftime('%Y-%m-%d')
        }

    # ============================================================
    # 5. å¤šå› ç´ å› æœåˆ†æ
    # ============================================================
    def analyze_all_factors(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†ææ‰€æœ‰å› ç´ çš„å› æœæ•ˆåº”"""
        print("\nğŸ¯ å¼€å§‹å¤šå› ç´ å› æœåˆ†æ...")

        results = {}

        # åˆ†æå› ç´ åˆ—è¡¨
        factors_to_analyze = [
            {
                'name': 'has_promotion',
                'display_name': 'ä¿ƒé”€æ´»åŠ¨',
                'confounders': ['is_weekend', 'is_holiday', 'day_of_week', 'unique_customers', 'category_diversity']
            },
            {
                'name': 'is_weekend',
                'display_name': 'å‘¨æœ«æ•ˆåº”',
                'confounders': ['is_holiday', 'unique_customers', 'has_promotion']
            },
            {
                'name': 'is_holiday',
                'display_name': 'èŠ‚å‡æ—¥æ•ˆåº”',
                'confounders': ['is_weekend', 'day_of_week', 'unique_customers']
            }
        ]

        # æ·»åŠ å¤©æ°”å› ç´ ï¼ˆå¦‚æœæœ‰æ•°æ®ï¼‰
        if 'is_hot' in df.columns:
            factors_to_analyze.extend([
                {
                    'name': 'is_hot',
                    'display_name': 'é«˜æ¸©å¤©æ°”',
                    'confounders': ['is_weekend', 'is_holiday', 'day_of_week', 'unique_customers']
                },
                {
                    'name': 'is_rainy',
                    'display_name': 'é›¨å¤©å¤©æ°”',
                    'confounders': ['is_weekend', 'is_holiday', 'day_of_week', 'temperature_mean']
                }
            ])

        # æ‰§è¡Œåˆ†æ
        for factor in factors_to_analyze:
            if factor['name'] in df.columns:
                result = self._analyze_single_factor_econml(
                    df, factor['name'], factor['display_name'], factor['confounders']
                )
                results[factor['name']] = result

        # äº¤äº’æ•ˆåº”åˆ†æ
        interaction_results = self._analyze_interactions(df)
        results['interactions'] = interaction_results

        # å¼‚è´¨æ€§åˆ†æ
        heterogeneity_results = self._analyze_heterogeneity(df)
        results['heterogeneity'] = heterogeneity_results

        self.analysis_results = results
        return results

    def _analyze_single_factor_econml(self, df: pd.DataFrame, treatment: str,
                                      treatment_name: str, confounders: List[str]) -> Dict[str, Any]:
        """ä½¿ç”¨EconMLåˆ†æå•ä¸ªå› ç´ """
        print(f"  ğŸ“Š åˆ†æ {treatment_name}...")

        # æ•°æ®é¢„å¤„ç†
        analysis_cols = [treatment, 'total_revenue'] + confounders
        clean_df = self._force_numeric(df, analysis_cols).dropna(subset=analysis_cols)

        if len(clean_df) < 50:
            return {'error': 'æ•°æ®ä¸è¶³', 'sample_size': len(clean_df)}

        try:
            Y = clean_df['total_revenue'].values
            T = clean_df[treatment].values.astype(int)
            X = clean_df[confounders].values

            # åˆ†å‰²æ•°æ®
            X_tr, X_te, T_tr, T_te, Y_tr, Y_te = train_test_split(
                X, T, Y, test_size=0.2, random_state=42
            )

            # ä½¿ç”¨LinearDMLï¼ˆæ›´ç¨³å®šï¼‰
            ldml = LinearDML(
                model_t='auto',
                model_y=RandomForestRegressor(n_estimators=100, max_depth=5),
                discrete_treatment=True,
                random_state=42
            )

            ldml.fit(Y_tr, T_tr, X=X_tr)

            # è®¡ç®—ATEå’Œç½®ä¿¡åŒºé—´
            ate = float(ldml.ate(X_te))

            # å°è¯•è·å–ç½®ä¿¡åŒºé—´
            try:
                ci_lower, ci_upper = ldml.ate_interval(X_te, alpha=0.05)
                ci_lower, ci_upper = float(ci_lower), float(ci_upper)
            except:
                # å¦‚æœæ— æ³•è®¡ç®—ç½®ä¿¡åŒºé—´ï¼Œä½¿ç”¨bootstrapä¼°è®¡
                ci_lower, ci_upper = ate - 1.96 * abs(ate) * 0.1, ate + 1.96 * abs(ate) * 0.1

            # è®¡ç®—å…¶ä»–ç»Ÿè®¡ä¿¡æ¯
            treatment_rate = clean_df[treatment].mean()
            treatment_group_mean = clean_df[clean_df[treatment] == 1]['total_revenue'].mean()
            control_group_mean = clean_df[clean_df[treatment] == 0]['total_revenue'].mean()

            print(f"    âœ… {treatment_name}: ATE = ${ate:.2f} [{ci_lower:.2f}, {ci_upper:.2f}]")

            return {
                'ate': ate,
                'ci_lower': ci_lower,
                'ci_upper': ci_upper,
                'treatment_rate': treatment_rate,
                'treatment_group_mean': treatment_group_mean,
                'control_group_mean': control_group_mean,
                'sample_size': len(clean_df),
                'significant': not (ci_lower <= 0 <= ci_upper)  # ç½®ä¿¡åŒºé—´ä¸åŒ…å«0
            }

        except Exception as e:
            print(f"    âŒ {treatment_name} åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}

    def _analyze_interactions(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æäº¤äº’æ•ˆåº”"""
        print("  ğŸ”„ åˆ†æäº¤äº’æ•ˆåº”...")

        interactions = {}

        # å®šä¹‰è¦åˆ†æçš„äº¤äº’å¯¹
        interaction_pairs = [
            ('is_rainy', 'has_promotion', 'é›¨å¤©ä¿ƒé”€äº¤äº’'),
            ('is_hot', 'has_promotion', 'é«˜æ¸©ä¿ƒé”€äº¤äº’'),
            ('is_weekend', 'has_promotion', 'å‘¨æœ«ä¿ƒé”€äº¤äº’'),
            ('is_holiday', 'is_weekend', 'èŠ‚å‡æ—¥å‘¨æœ«äº¤äº’')
        ]

        for factor1, factor2, name in interaction_pairs:
            if factor1 in df.columns and factor2 in df.columns:
                interaction_result = self._calculate_interaction_effect(df, factor1, factor2, name)
                interactions[f"{factor1}_x_{factor2}"] = interaction_result

        return interactions

    def _calculate_interaction_effect(self, df: pd.DataFrame, factor1: str, factor2: str, name: str) -> Dict[str, Any]:
        """è®¡ç®—äº¤äº’æ•ˆåº”"""
        try:
            # åˆ›å»ºå››ä¸ªç»„åˆçš„å¹³å‡è¥æ”¶
            results = {}
            for val1 in [0, 1]:
                for val2 in [0, 1]:
                    mask = (df[factor1] == val1) & (df[factor2] == val2)
                    if mask.sum() > 5:  # è‡³å°‘5ä¸ªæ ·æœ¬
                        group_revenue = df[mask]['total_revenue'].mean()
                        group_size = mask.sum()
                        results[f"{val1}_{val2}"] = {'revenue': group_revenue, 'count': group_size}

            if len(results) == 4:  # æ‰€æœ‰å››ä¸ªç»„åˆéƒ½æœ‰æ•°æ®
                # è®¡ç®—äº¤äº’æ•ˆåº”
                baseline = results['0_0']['revenue']
                factor1_effect = results['1_0']['revenue'] - baseline
                factor2_effect = results['0_1']['revenue'] - baseline
                combined_effect = results['1_1']['revenue'] - baseline
                interaction_effect = combined_effect - factor1_effect - factor2_effect

                return {
                    'interaction_effect': interaction_effect,
                    'factor1_main_effect': factor1_effect,
                    'factor2_main_effect': factor2_effect,
                    'combined_effect': combined_effect,
                    'group_details': results,
                    'name': name
                }
            else:
                return {'error': 'æ•°æ®ä¸è¶³', 'name': name}

        except Exception as e:
            return {'error': str(e), 'name': name}

    def _analyze_heterogeneity(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æå¼‚è´¨æ€§æ•ˆåº”"""
        print("  ğŸ” åˆ†æå¼‚è´¨æ€§æ•ˆåº”...")

        heterogeneity = {}

        # æŒ‰åº—é“ºåˆ†æä¿ƒé”€æ•ˆåº”å¼‚è´¨æ€§
        if 'has_promotion' in df.columns:
            store_effects = {}
            for store_id in df['location_id'].unique():
                store_df = df[df['location_id'] == store_id].copy()
                if len(store_df) > 30 and store_df['has_promotion'].sum() > 5:  # è¶³å¤Ÿçš„æ•°æ®å’Œä¿ƒé”€æ ·æœ¬
                    treated_mean = store_df[store_df['has_promotion'] == 1]['total_revenue'].mean()
                    control_mean = store_df[store_df['has_promotion'] == 0]['total_revenue'].mean()
                    effect = treated_mean - control_mean
                    store_effects[store_id] = {
                        'effect': effect,
                        'treated_mean': treated_mean,
                        'control_mean': control_mean,
                        'sample_size': len(store_df)
                    }

            heterogeneity['promotion_by_store'] = store_effects

        # æŒ‰å¤©æ°”æ¡ä»¶åˆ†æå¼‚è´¨æ€§
        if 'is_hot' in df.columns and 'has_promotion' in df.columns:
            weather_effects = {}
            weather_conditions = ['is_hot', 'is_rainy', 'is_mild']

            for condition in weather_conditions:
                if condition in df.columns:
                    weather_df = df[df[condition] == 1]
                    if len(weather_df) > 20 and weather_df['has_promotion'].sum() > 3:
                        treated_mean = weather_df[weather_df['has_promotion'] == 1]['total_revenue'].mean()
                        control_mean = weather_df[weather_df['has_promotion'] == 0]['total_revenue'].mean()
                        effect = treated_mean - control_mean
                        weather_effects[condition] = {
                            'effect': effect,
                            'treated_mean': treated_mean,
                            'control_mean': control_mean,
                            'sample_size': len(weather_df)
                        }

            heterogeneity['promotion_by_weather'] = weather_effects

        # æŒ‰äº§å“ç±»åˆ«åˆ†æï¼ˆæ–°å¢ï¼‰
        if 'has_promotion' in df.columns:
            category_effects = self._analyze_category_heterogeneity(df)
            if category_effects:
                heterogeneity['promotion_by_category'] = category_effects

        return heterogeneity

    def _analyze_category_heterogeneity(self, df: pd.DataFrame) -> Dict[str, Any]:
        """æŒ‰äº§å“ç±»åˆ«åˆ†æå¼‚è´¨æ€§"""
        category_effects = {}

        # å®šä¹‰äº§å“ç±»åˆ«æ•ˆåº”åˆ†æ
        category_columns = [
            ('tea_drinks_orders', 'èŒ¶é¥®ç±»'),
            ('coffee_orders', 'å’–å•¡ç±»'),
            ('food_orders', 'å°é£Ÿç±»'),
            ('caffeine_free_orders', 'æ— å’–å•¡å› é¥®å“'),
            ('new_product_orders', 'æ–°å“')
        ]

        for col, name in category_columns:
            if col in df.columns:
                # åˆ†æè¯¥ç±»åˆ«åœ¨ä¿ƒé”€å’Œéä¿ƒé”€æ—¶çš„è¡¨ç°
                promo_df = df[df['has_promotion'] == 1]
                no_promo_df = df[df['has_promotion'] == 0]

                if len(promo_df) > 10 and len(no_promo_df) > 10:
                    promo_avg = promo_df[col].mean()
                    no_promo_avg = no_promo_df[col].mean()

                    category_effects[name] = {
                        'promotion_avg': promo_avg,
                        'no_promotion_avg': no_promo_avg,
                        'lift': (promo_avg - no_promo_avg) / (no_promo_avg + 1e-6),
                        'absolute_difference': promo_avg - no_promo_avg
                    }

        return category_effects

    # ============================================================
    # 6. ç¼ºå¤±æ•°æ®æ¥å£ï¼ˆé¢„ç•™ï¼‰
    # ============================================================
    def get_inventory_data(self, item_ids: List[str] = None) -> pd.DataFrame:
        """è·å–åº“å­˜æ•°æ® - é¢„ç•™æ¥å£"""
        print("âš ï¸ åº“å­˜æ•°æ®æ¥å£é¢„ç•™ï¼Œæš‚æ— å®é™…æ•°æ®")
        # è¿”å›ç©ºDataFrameï¼Œä¿æŒæ¥å£ä¸€è‡´æ€§
        return pd.DataFrame(columns=['item_id', 'location_id', 'current_stock', 'safety_stock'])

    def get_traffic_data(self, location_ids: List[str] = None) -> pd.DataFrame:
        """è·å–å®¢æµæ•°æ® - é¢„ç•™æ¥å£"""
        print("âš ï¸ å®¢æµæ•°æ®æ¥å£é¢„ç•™ï¼Œæš‚æ— å®é™…æ•°æ®")
        # è¿”å›ç©ºDataFrame
        return pd.DataFrame(columns=['date', 'location_id', 'hour', 'visitor_count'])

    def get_supply_chain_data(self) -> pd.DataFrame:
        """è·å–ä¾›åº”é“¾æ•°æ® - é¢„ç•™æ¥å£"""
        print("âš ï¸ ä¾›åº”é“¾æ•°æ®æ¥å£é¢„ç•™ï¼Œæš‚æ— å®é™…æ•°æ®")
        # è¿”å›ç©ºDataFrame
        return pd.DataFrame(columns=['item_id', 'supplier_id', 'lead_time', 'reliability_score'])

    # ============================================================
    # 7. å·¥å…·å‡½æ•°
    # ============================================================
    @staticmethod
    def _force_numeric(df, cols):
        """å¼ºåˆ¶è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ï¼Œå¤„ç†Decimal"""
        out = df.copy()
        for c in cols:
            if c in out.columns:
                if out[c].dtype == 'object':
                    try:
                        out[c] = pd.to_numeric(out[c], errors='coerce')
                    except:
                        import decimal
                        def convert_decimal(x):
                            if isinstance(x, decimal.Decimal):
                                return float(x)
                            return x

                        out[c] = out[c].apply(convert_decimal)
                        out[c] = pd.to_numeric(out[c], errors='coerce')
                else:
                    out[c] = pd.to_numeric(out[c], errors='coerce')
        return out

    # ============================================================
    # 8. å¿«é€Ÿåˆ†ææ¥å£ï¼ˆå¢å¼ºç‰ˆï¼‰
    # ============================================================
    def run_complete_analysis(self, start_date: str, end_date: str, include_forecast: bool = True) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        print("ğŸš€ å¼€å§‹å®Œæ•´å› æœæ¨æ–­åˆ†æï¼ˆå¢å¼ºç‰ˆï¼‰...")
        print("=" * 60)

        # 1. æ•°æ®åŠ è½½
        sales_df = self.load_integrated_data(start_date, end_date)

        # æŸäº›æƒ…å†µä¸‹ç‚¹å‡»å±‹è¿”å›çš„æ•°æ®å¯èƒ½ç¼ºå°‘å·ä¿¡æ¯ï¼Œ
        # åç»­å¤©æ°”ç‰¹å¾å’Œæ±‡æ€»ç»Ÿè®¡éƒ½ä¾èµ– state åˆ—ã€‚ä¸ºé¿å…
        # KeyErrorï¼Œè¿™é‡Œè¿›è¡Œå…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœç¼ºå°‘ state åˆ—ï¼Œ
        # å°è¯•ä»é—¨åº—åç§°ä¸­è§£æå·ä»£ç ï¼Œè‹¥ä»å¤±è´¥åˆ™ä½¿ç”¨é»˜è®¤å€¼ã€‚
        if 'state' not in sales_df.columns:
            if 'location_name' in sales_df.columns:
                sales_df['state'] = (
                    sales_df['location_name']
                    .astype(str)
                    .str.extract(r'-([A-Z]{2})$')[0]
                    .fillna('CA')
                )
            else:
                sales_df['state'] = 'CA'

        # 2. åŠ è½½é¢å¤–æ•°æ®
        customer_df = self.load_customer_profile_data(start_date, end_date)
        promotion_df = self.load_promotion_sales_data(start_date, end_date)

        # 3. å¤©æ°”æ•°æ®
        weather_df = self.get_weather_data(start_date, end_date, sales_df)

        # 4. ç‰¹å¾å·¥ç¨‹
        enhanced_df = self.create_all_features(sales_df, weather_df)

        # 5. å› æœåˆ†æ
        analysis_results = self.analyze_all_factors(enhanced_df)

        # 6. é”€å”®é¢„æµ‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
        forecast_results = None
        if include_forecast:
            forecast_results = self.create_sales_forecast(days_ahead=7)

        # 7. æ±‡æ€»åˆ†æä¿¡æ¯
        summary = {
            'analysis_period': {'start': start_date, 'end': end_date},
            'data_summary': {
                'total_records': len(enhanced_df),
                'stores_count': enhanced_df['location_id'].nunique(),
                'states_count': enhanced_df['state'].nunique(),
                'date_range_days': (pd.to_datetime(end_date) - pd.to_datetime(start_date)).days + 1,
                'customers_analyzed': len(customer_df) if customer_df is not None else 0,
                'promotions_analyzed': len(promotion_df) if promotion_df is not None else 0
            },
            'features_created': len(enhanced_df.columns),
            'analysis_results': analysis_results,
            'forecast_results': forecast_results,
            'raw_data': self.raw_data,
            'enhanced_data': self.enhanced_data,
            'customer_data': self.customer_data,
            'promotion_data': self.promotion_data
        }

        print("âœ… å®Œæ•´åˆ†æå®Œæˆï¼")
        return summary

    def create_key_metrics_summary(self) -> Dict[str, Any]:
        """åˆ›å»ºå…³é”®æŒ‡æ ‡æ‘˜è¦"""
        if self.enhanced_data is None:
            return {}

        df = self.enhanced_data

        # è®¡ç®—å…³é”®æŒ‡æ ‡
        metrics = {
            'sales_revenue': {
                'last_7d': df[df['date'] >= df['date'].max() - timedelta(days=6)]['total_revenue'].sum(),
                'last_14d': df[df['date'] >= df['date'].max() - timedelta(days=13)]['total_revenue'].sum(),
                'change': 0  # å°†è®¡ç®—å‘¨ç¯æ¯”å˜åŒ–
            },
            'orders_count': {
                'last_7d': df[df['date'] >= df['date'].max() - timedelta(days=6)]['order_count'].sum(),
                'last_14d': df[df['date'] >= df['date'].max() - timedelta(days=13)]['order_count'].sum(),
                'change': 0
            },
            'average_order_value': {
                'last_7d': df[df['date'] >= df['date'].max() - timedelta(days=6)]['avg_order_value'].mean(),
                'last_14d': df[df['date'] >= df['date'].max() - timedelta(days=13)]['avg_order_value'].mean(),
                'change': 0
            },
            'unique_customers': {
                'last_7d': df[df['date'] >= df['date'].max() - timedelta(days=6)]['unique_customers'].sum(),
                'last_14d': df[df['date'] >= df['date'].max() - timedelta(days=13)]['unique_customers'].sum(),
                'change': 0
            }
        }

        # è®¡ç®—å˜åŒ–ç‡
        for metric in metrics:
            last_7d = metrics[metric]['last_7d']
            prev_7d = metrics[metric]['last_14d'] - last_7d
            if prev_7d > 0:
                metrics[metric]['change'] = ((last_7d - prev_7d) / prev_7d) * 100

        return metrics