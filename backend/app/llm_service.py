# backend/app/llm_service.py
"""
ä¼˜åŒ–åçš„LLMæœåŠ¡ - æ›´æ™ºèƒ½çš„å“åº”ç”Ÿæˆ
"""
import json
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
from openai import AzureOpenAI
from decimal import Decimal

from app.config import settings
from app.utils import get_weather_summary

logger = logging.getLogger(__name__)


def convert_decimal_to_str(obj):
    """é€’å½’è½¬æ¢Decimalç±»å‹ä¸ºå­—ç¬¦ä¸²"""
    if isinstance(obj, Decimal):
        return str(obj)
    elif isinstance(obj, dict):
        return {key: convert_decimal_to_str(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_decimal_to_str(item) for item in obj]
    else:
        return obj


class LLMService:
    """å¢å¼ºç‰ˆLLMæœåŠ¡ - æ›´æ™ºèƒ½çš„æ„å›¾è¯†åˆ«å’Œå“åº”ç”Ÿæˆ"""

    def __init__(self):
        self.client = AzureOpenAI(
            api_key=settings.OPENAI_API_KEY,
            azure_endpoint=settings.OPENAI_BASE_URL,
            api_version=settings.OPENAI_API_VERSION
        )
        self.model = settings.OPENAI_MODEL

    async def parse_query_intent(self, query: str) -> Dict[str, Any]:
        """ä½¿ç”¨LLMè¿›è¡Œæ„å›¾è¯†åˆ«"""
        try:
            # è·å–å½“å‰æ—¶é—´å’Œå¤©æ°”ä¿¡æ¯
            time_weather = get_weather_summary(40.71, -74.01, timezone="America/New_York")

            prompt = f"""
            åˆ†æç”¨æˆ·æŸ¥è¯¢çš„æ„å›¾å¹¶æå–å…³é”®ä¿¡æ¯ã€‚

            å½“å‰ç¯å¢ƒä¿¡æ¯ï¼š
            {time_weather}

            ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

            è¯·è¿”å›JSONæ ¼å¼çš„æ„å›¾åˆ†æç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
            - intent_type: æ„å›¾ç±»å‹ï¼Œå¯é€‰å€¼ï¼š
              * forecast: é¢„æµ‹ç±»æŸ¥è¯¢
              * data_query: æ•°æ®æŸ¥è¯¢ï¼ˆæŸ¥çœ‹å…·ä½“æ•°æ®ï¼‰
              * analysis: åˆ†æç±»æŸ¥è¯¢ï¼ˆå› æœåˆ†æã€è¶‹åŠ¿åˆ†æç­‰ï¼‰
              * daily_report: æ—¥æŠ¥ç±»æŸ¥è¯¢
              * recommendation: å»ºè®®ç±»æŸ¥è¯¢
              * general: ä¸€èˆ¬å¯¹è¯
            - entities: æå–çš„å®ä½“ä¿¡æ¯ï¼Œå¦‚ï¼š
              * time_range: æ—¶é—´èŒƒå›´
              * metrics: æ¶‰åŠçš„æŒ‡æ ‡
              * dimensions: ç»´åº¦ï¼ˆå¦‚äº§å“ã€å®¢æˆ·ç­‰ï¼‰
              * query_target: æŸ¥è¯¢ç›®æ ‡
            - needs_data: æ˜¯å¦éœ€è¦æŸ¥è¯¢æ•°æ®ï¼ˆå¸ƒå°”å€¼ï¼‰
            - confidence: ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰
            - query: æ¸…ç†åçš„æŸ¥è¯¢è¯­å¥
            - parameters: å…¶ä»–å‚æ•°

            ç¤ºä¾‹ï¼š
            - "é¢„æµ‹æ˜å¤©çš„é”€å”®" -> intent_type: "forecast", time_range: "æ˜å¤©"
            - "ä¸ºä»€ä¹ˆä»Šå¤©é”€å”®ä¸‹é™" -> intent_type: "analysis", time_range: "ä»Šå¤©"
            - "æŸ¥çœ‹æœ¬å‘¨è®¢å•æ•°" -> intent_type: "data_query", time_range: "æœ¬å‘¨", metrics: ["è®¢å•æ•°"]
            """

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": query}
                ],
                temperature=0.3,
                response_format={"type": "json_object"}
            )

            intent = json.loads(response.choices[0].message.content)
            logger.info(f"LLMæ„å›¾è¯†åˆ«ç»“æœ: {intent}")
            return intent

        except Exception as e:
            logger.error(f"LLMæ„å›¾è¯†åˆ«å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤æ„å›¾
            return {
                "intent_type": "general",
                "entities": {},
                "needs_data": False,
                "confidence": 0.0,
                "query": query
            }

    async def generate_response(self,
                                user_message: str,
                                data: Optional[Dict[str, Any]] = None,
                                history: List[Dict[str, str]] = None) -> Dict[str, Any]:
        """ç”Ÿæˆæ™ºèƒ½å“åº” - å……åˆ†åˆ©ç”¨LLMèƒ½åŠ›"""

        # è§£ææ„å›¾
        intent = await self.parse_query_intent(user_message)

        # æ„å»ºå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯
        system_prompt = self._build_enhanced_system_prompt()

        # å‡†å¤‡æ•°æ®ä¸Šä¸‹æ–‡
        data_context = self._prepare_data_context(data, intent) if data else None

        # ä½¿ç”¨LLMç”Ÿæˆå“åº”
        try:
            messages = [
                {"role": "system", "content": system_prompt}
            ]

            # æ·»åŠ å†å²å¯¹è¯ï¼ˆåªä¿ç•™æœ€è¿‘5æ¡ï¼‰
            if history:
                for msg in history[-5:]:
                    messages.append({
                        "role": "user" if msg["role"] == "user" else "assistant",
                        "content": msg["content"]
                    })

            # æ„å»ºå½“å‰æ¶ˆæ¯
            current_message = self._build_current_message(user_message, data_context, intent)
            messages.append({"role": "user", "content": current_message})

            # è°ƒç”¨LLM
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=2048
            )

            # è§£æå“åº”
            bot_message = response.choices[0].message.content

            # æ ¹æ®æ„å›¾ç±»å‹åŒ…è£…æ•°æ®
            response_data = self._wrap_response_data(data, intent) if data else None

            return {
                "message": bot_message,
                "data": response_data,
                "intent": intent
            }

        except Exception as e:
            logger.error(f"LLMå“åº”ç”Ÿæˆå¤±è´¥: {e}")
            return self._generate_fallback_response(user_message, data, intent)

    def _build_enhanced_system_prompt(self) -> str:
        """æ„å»ºå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯"""
        time_weather = get_weather_summary(40.71, -74.01, timezone="America/New_York")

        return f"""
        ä½ æ˜¯UMeæ•°æ®åŠ©æ‰‹ï¼Œä¸€ä¸ªä¸“ä¸šçš„é›¶å”®æ•°æ®åˆ†æAIåŠ©ç†ã€‚ä½ çš„ç›®æ ‡æ˜¯å¸®åŠ©å•†å®¶ç†è§£æ•°æ®ã€å‘ç°æ´å¯Ÿã€ä¼˜åŒ–è¿è¥ã€‚

        å½“å‰ç¯å¢ƒä¿¡æ¯ï¼š
        {time_weather}

        ä¿ƒé”€ä¿¡æ¯ï¼š7æœˆ29åˆ°7æœˆ31æ—¥ï¼ŒUme-Teaå•†å®¶å¼€å§‹å”®å–ä»£é‡‘åˆ¸ï¼Œé¢é¢100ç¾å…ƒ

        ## ä½ çš„æ ¸å¿ƒèƒ½åŠ›ï¼š
        1. **æ•°æ®åˆ†æ**ï¼šæ·±å…¥åˆ†æé”€å”®æ•°æ®ï¼Œå‘ç°è¶‹åŠ¿å’Œæ¨¡å¼
        2. **å› æœæ¨ç†**ï¼šè¯†åˆ«å½±å“ä¸šåŠ¡çš„å…³é”®å› ç´ 
        3. **é¢„æµ‹å»ºæ¨¡**ï¼šåŸºäºå†å²æ•°æ®é¢„æµ‹æœªæ¥è¶‹åŠ¿
        4. **æ™ºèƒ½å»ºè®®**ï¼šæä¾›å¯æ“ä½œçš„ä¼˜åŒ–å»ºè®®
        5. **è‡ªç„¶å¯¹è¯**ï¼šç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šå¤æ‚æ•°æ®

        ## å›ç­”åŸåˆ™ï¼š
        1. **æ•°æ®é©±åŠ¨**ï¼šæ‰€æœ‰ç»“è®ºéƒ½åŸºäºå®é™…æ•°æ®
        2. **æ´å¯Ÿä¼˜å…ˆ**ï¼šä¸åªæ˜¯å±•ç¤ºæ•°æ®ï¼Œè¦æä¾›æ´å¯Ÿ
        3. **è¡ŒåŠ¨å¯¼å‘**ï¼šæ¯ä¸ªåˆ†æéƒ½è¦æœ‰å¯æ‰§è¡Œçš„å»ºè®®
        4. **ç®€æ´æ˜äº†**ï¼šé¿å…å†—é•¿ï¼Œçªå‡ºé‡ç‚¹
        5. **æƒ…å¢ƒæ„ŸçŸ¥**ï¼šè€ƒè™‘æ—¶é—´ã€å¤©æ°”ã€èŠ‚å‡æ—¥ç­‰å› ç´ 

        ## å› æœåˆ†ææ¡†æ¶ï¼š
        å½“åˆ†æé”€å”®æ³¢åŠ¨æ—¶ï¼Œè€ƒè™‘ä»¥ä¸‹å› ç´ åŠå…¶å½±å“ï¼š

        ### ä¸»æ•ˆåº”ï¼ˆå¹³å‡å½±å“ï¼‰ï¼š
        - å‘¨æœ«æ•ˆåº”ï¼š+$2,088
        - èŠ‚å‡æ—¥æ•ˆåº”ï¼š+$369
        - ä¿ƒé”€æ•ˆåº”ï¼š+$193
        - é«˜æ¸©å¤©æ°”ï¼š+$23
        - é›¨å¤©ï¼š-$118

        ### äº¤äº’æ•ˆåº”ï¼ˆç»„åˆå½±å“ï¼‰ï¼š
        - å‘¨æœ« + ä¿ƒé”€ï¼šé¢å¤–+$765
        - é«˜æ¸© + ä¿ƒé”€ï¼šé¢å¤–-$1,426
        - é›¨å¤© + ä¿ƒé”€ï¼šé¢å¤–-$448

        ## å›ç­”æ ¼å¼æŒ‡å—ï¼š

        ### å¯¹äºæ•°æ®æŸ¥è¯¢ï¼š
        - å…ˆç»™å‡ºæ ¸å¿ƒæ•°å­—
        - è§£é‡Šæ•°æ®å«ä¹‰
        - æä¾›å¯¹æ¯”æˆ–è¶‹åŠ¿
        - ç»™å‡ºä¼˜åŒ–å»ºè®®

        ### å¯¹äºé¢„æµ‹è¯·æ±‚ï¼š
        - è¯´æ˜é¢„æµ‹ç»“æœ
        - è§£é‡Šé¢„æµ‹ä¾æ®
        - æŒ‡å‡ºå…³é”®å‡è®¾
        - æä¾›ç½®ä¿¡åŒºé—´

        ### å¯¹äºåˆ†æè¯·æ±‚ï¼š
        - è¯†åˆ«å…³é”®å‘ç°
        - è§£é‡Šå› æœå…³ç³»
        - é‡åŒ–å½±å“ç¨‹åº¦
        - æä¾›æ”¹è¿›æ–¹æ¡ˆ

        ## è¯­è¨€é£æ ¼ï¼š
        - ä¸“ä¸šä½†å‹å¥½
        - ä½¿ç”¨æ•°æ®æ”¯æ’‘è§‚ç‚¹
        - é€‚å½“ä½¿ç”¨emojiå¢åŠ å¯è¯»æ€§
        - åˆ†ç‚¹è¯´æ˜ï¼Œç»“æ„æ¸…æ™°
        - é¿å…è¿‡åº¦æŠ€æœ¯åŒ–çš„æœ¯è¯­

        è®°ä½ï¼šä½ çš„ç›®æ ‡æ˜¯è®©å•†å®¶èƒ½å¤Ÿå¿«é€Ÿç†è§£æ•°æ®ã€åšå‡ºå†³ç­–ã€æ”¹å–„ä¸šç»©ã€‚
        """

    def _prepare_data_context(self, data: Dict[str, Any], intent: Dict[str, Any]) -> str:
        """å‡†å¤‡æ•°æ®ä¸Šä¸‹æ–‡"""
        if not data:
            return ""

        # è½¬æ¢Decimalç±»å‹
        data = convert_decimal_to_str(data)

        context_parts = []

        # æ ¹æ®æ„å›¾ç±»å‹å‡†å¤‡ä¸åŒçš„ä¸Šä¸‹æ–‡
        if intent["intent_type"] == "forecast":
            if "forecast" in data:
                context_parts.append(f"é¢„æµ‹æ•°æ®ï¼š{json.dumps(data['forecast'], ensure_ascii=False)}")
            if "chart_data" in data:
                context_parts.append(f"å†å²è¶‹åŠ¿ï¼šæœ€è¿‘7å¤©å¹³å‡é”€å”®${data.get('avg_sales', 0):.2f}")

        elif intent["intent_type"] == "analysis":
            if "causal_effects" in data:
                context_parts.append(f"å› æœåˆ†æç»“æœï¼š{json.dumps(data['causal_effects'], ensure_ascii=False)}")
            if "trends" in data:
                context_parts.append(f"è¶‹åŠ¿åˆ†æï¼š{json.dumps(data['trends'], ensure_ascii=False)}")

        elif intent["intent_type"] == "data_query":
            # æå–å…³é”®æŒ‡æ ‡
            metrics = {}
            for key in ["total_revenue", "total_orders", "unique_customers", "avg_order_value"]:
                if key in data:
                    metrics[key] = data[key]
            if metrics:
                context_parts.append(f"æŸ¥è¯¢ç»“æœï¼š{json.dumps(metrics, ensure_ascii=False)}")

            # æ·»åŠ é¢å¤–æ•°æ®
            if "additional_data" in data:
                context_parts.append(f"è¯¦ç»†æ•°æ®ï¼š{json.dumps(data['additional_data'], ensure_ascii=False)}")

        return "\n".join(context_parts)

    def _build_current_message(self, user_message: str, data_context: str, intent: Dict[str, Any]) -> str:
        """æ„å»ºå½“å‰æ¶ˆæ¯"""
        message_parts = [f"ç”¨æˆ·é—®é¢˜ï¼š{user_message}"]

        if data_context:
            message_parts.append(f"\nç›¸å…³æ•°æ®ï¼š\n{data_context}")

        message_parts.append(f"\næ„å›¾ç±»å‹ï¼š{intent['intent_type']}")

        # æ·»åŠ ç‰¹å®šæŒ‡ä»¤
        if intent["intent_type"] == "forecast":
            message_parts.append("\nè¯·åŸºäºæ•°æ®ç”Ÿæˆé”€å”®é¢„æµ‹åˆ†æï¼ŒåŒ…æ‹¬ï¼šé¢„æµ‹ç»“æœè§£è¯»ã€å…³é”®å‡è®¾ã€é£é™©æç¤ºã€ä¼˜åŒ–å»ºè®®ã€‚")
        elif intent["intent_type"] == "analysis":
            message_parts.append("\nè¯·è¿›è¡Œæ·±åº¦åˆ†æï¼Œè¯†åˆ«å…³é”®å½±å“å› ç´ ï¼Œé‡åŒ–å„å› ç´ çš„å½±å“ç¨‹åº¦ï¼Œå¹¶æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®ã€‚")
        elif intent["intent_type"] == "data_query":
            message_parts.append("\nè¯·æ¸…æ™°å±•ç¤ºæŸ¥è¯¢ç»“æœï¼Œè§£é‡Šæ•°æ®å«ä¹‰ï¼Œæä¾›ç›¸å…³æ´å¯Ÿå’Œå»ºè®®ã€‚")
        else:
            message_parts.append("\nè¯·æä¾›ä¸“ä¸šã€æœ‰æ´å¯ŸåŠ›çš„å›ç­”ï¼Œç¡®ä¿å†…å®¹å¯¹å•†å®¶å†³ç­–æœ‰å¸®åŠ©ã€‚")

        return "\n".join(message_parts)

    def _wrap_response_data(self, data: Dict[str, Any], intent: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¹æ®æ„å›¾ç±»å‹åŒ…è£…å“åº”æ•°æ®"""
        if not data:
            return None

        # æ ¹æ®æ„å›¾ç±»å‹ç¡®å®šå±•ç¤ºç±»å‹
        display_type_map = {
            "forecast": "forecast",
            "analysis": "causal_analysis",
            "data_query": "metrics_cards",
            "daily_report": "daily_report"
        }

        display_type = display_type_map.get(intent["intent_type"], "general")

        return {
            "type": display_type,
            "content": data,
            "display_type": display_type
        }

    def _generate_fallback_response(self, user_message: str, data: Optional[Dict[str, Any]], intent: Dict[str, Any]) -> \
    Dict[str, Any]:
        """ç”Ÿæˆé™çº§å“åº”"""
        fallback_messages = {
            "forecast": "æ­£åœ¨ä¸ºæ‚¨ç”Ÿæˆé”€å”®é¢„æµ‹ï¼Œè¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿ...",
            "analysis": "æ­£åœ¨åˆ†ææ•°æ®ä¸­ï¼Œé©¬ä¸Šä¸ºæ‚¨å‘ˆç°ç»“æœ...",
            "data_query": "æ­£åœ¨æŸ¥è¯¢æ•°æ®ï¼Œè¯·ç¨å€™...",
            "daily_report": "æ­£åœ¨ç”Ÿæˆä»Šæ—¥æŠ¥å‘Š...",
            "general": """æˆ‘ç†è§£æ‚¨çš„é—®é¢˜ã€‚è®©æˆ‘ä¸ºæ‚¨æä¾›ä¸€äº›å¸®åŠ©ï¼š
            
            å¦‚æœæ‚¨æƒ³è¦ï¼š
            â€¢ ğŸ“ˆ é¢„æµ‹é”€å”®ï¼šå¯ä»¥è¯´"é¢„æµ‹æœªæ¥7å¤©çš„é”€å”®"
            â€¢ ğŸ“Š æŸ¥è¯¢æ•°æ®ï¼šå¯ä»¥è¯´"æŸ¥è¯¢æ€»ç”¨æˆ·æ•°"æˆ–"ä»Šå¤©çš„è®¢å•æ•°"
            â€¢ ğŸ“‰ åˆ†æè¶‹åŠ¿ï¼šå¯ä»¥è¯´"åˆ†ææœ¬å‘¨é”€å”®è¶‹åŠ¿"
            â€¢ ğŸ“‹ æŸ¥çœ‹æŠ¥å‘Šï¼šå¯ä»¥è¯´"æ˜¾ç¤ºä»Šæ—¥æ•°æ®æŠ¥å‘Š"
            
            è¯·é—®æ‚¨å…·ä½“æƒ³äº†è§£ä»€ä¹ˆï¼Ÿ"""
        }

        return {
            "message": fallback_messages.get(intent["intent_type"], fallback_messages["general"]),
            "data": self._wrap_response_data(data, intent) if data else None,
            "intent": intent
        }

    async def generate_smart_insights(self, data: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ™ºèƒ½æ´å¯Ÿ - ä½¿ç”¨LLMåˆ†ææ•°æ®æ¨¡å¼"""
        try:
            data_str = json.dumps(convert_decimal_to_str(data), ensure_ascii=False)

            prompt = f"""
            åŸºäºä»¥ä¸‹æ•°æ®ï¼Œç”Ÿæˆ3-5ä¸ªå…³é”®ä¸šåŠ¡æ´å¯Ÿï¼š

            æ•°æ®ï¼š{data_str}

            è¦æ±‚ï¼š
            1. æ¯ä¸ªæ´å¯Ÿéƒ½è¦æœ‰æ•°æ®æ”¯æ’‘
            2. çªå‡ºå¼‚å¸¸å’Œæœºä¼š
            3. æä¾›å¯æ‰§è¡Œçš„å»ºè®®
            4. ç”¨ç®€æ´çš„è¯­è¨€è¡¨è¾¾

            è¿”å›JSONæ ¼å¼ï¼š{{"insights": ["æ´å¯Ÿ1", "æ´å¯Ÿ2", ...]}}
            """

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æä¸“å®¶ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                response_format={"type": "json_object"}
            )

            result = json.loads(response.choices[0].message.content)
            return result.get("insights", [])

        except Exception as e:
            logger.error(f"ç”Ÿæˆæ´å¯Ÿå¤±è´¥: {e}")
            return []

    async def generate_recommendations(self, analysis_results: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ™ºèƒ½å»ºè®® - åŸºäºåˆ†æç»“æœ"""
        try:
            data_str = json.dumps(convert_decimal_to_str(analysis_results), ensure_ascii=False)

            prompt = f"""
            åŸºäºä»¥ä¸‹åˆ†æç»“æœï¼Œç”Ÿæˆå…·ä½“çš„ä¸šåŠ¡ä¼˜åŒ–å»ºè®®ï¼š

            åˆ†æç»“æœï¼š{data_str}

            è¦æ±‚ï¼š
            1. æ¯ä¸ªå»ºè®®éƒ½è¦å…·ä½“å¯æ‰§è¡Œ
            2. åŒ…å«é¢„æœŸæ•ˆæœ
            3. æ ‡æ˜ä¼˜å…ˆçº§ï¼ˆé«˜/ä¸­/ä½ï¼‰
            4. è€ƒè™‘å®æ–½éš¾åº¦

            è¿”å›JSONæ ¼å¼ï¼š
            {{
                "recommendations": [
                    {{
                        "title": "å»ºè®®æ ‡é¢˜",
                        "description": "å…·ä½“æè¿°",
                        "expected_impact": "é¢„æœŸæ•ˆæœ",
                        "priority": "é«˜/ä¸­/ä½",
                        "difficulty": "æ˜“/ä¸­/éš¾"
                    }}
                ]
            }}
            """

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªé›¶å”®ä¸šåŠ¡é¡¾é—®ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                response_format={"type": "json_object"}
            )

            result = json.loads(response.choices[0].message.content)
            return result.get("recommendations", [])

        except Exception as e:
            logger.error(f"ç”Ÿæˆå»ºè®®å¤±è´¥: {e}")
            return []