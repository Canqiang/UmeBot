"""
LLMæœåŠ¡
å¤„ç†è‡ªç„¶è¯­è¨€ç†è§£å’Œç”Ÿæˆ
"""

from typing import Dict, List, Any, Optional
from datetime import datetime
import json
import re
from openai import AsyncOpenAI
from app.config import settings


class LLMService:
    """LLMæœåŠ¡ç±»"""

    def __init__(self):
        self.client = AsyncOpenAI(
            api_key=settings.OPENAI_API_KEY,
            base_url=settings.OPENAI_BASE_URL
        )
        self.model = settings.OPENAI_MODEL

        # ç³»ç»Ÿæç¤ºè¯
        self.system_prompt = """
        ä½ æ˜¯UMeèŒ¶é¥®çš„æ™ºèƒ½æ•°æ®åŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·åˆ†æå’Œç†è§£ä¸šåŠ¡æ•°æ®ã€‚

        ä½ çš„èŒè´£ï¼š
        1. è§£ç­”å…³äºé”€å”®ã€å®¢æˆ·ã€ä¿ƒé”€ç­‰ä¸šåŠ¡æ•°æ®çš„é—®é¢˜
        2. æä¾›æ•°æ®æ´å¯Ÿå’Œä¸šåŠ¡å»ºè®®
        3. è§£é‡Šå› æœåˆ†æç»“æœ
        4. é¢„æµ‹æœªæ¥è¶‹åŠ¿

        å›ç­”åŸåˆ™ï¼š
        1. åŸºäºæ•°æ®è¯´è¯ï¼Œç”¨æ•°å­—æ”¯æ’‘è§‚ç‚¹
        2. è¯­è¨€ä¸“ä¸šä½†æ˜“æ‡‚ï¼Œé¿å…è¿‡äºæŠ€æœ¯åŒ–
        3. ä¸»åŠ¨æä¾›å¯è¡Œçš„ä¸šåŠ¡å»ºè®®
        4. é€‚å½“ä½¿ç”¨emojiè®©å¯¹è¯æ›´å‹å¥½
        5. ç»“æ„åŒ–å±•ç¤ºå¤æ‚ä¿¡æ¯ï¼ˆä½¿ç”¨åˆ—è¡¨ã€è¡¨æ ¼ç­‰ï¼‰

        æ•°æ®è¯´æ˜ï¼š
        - è¥æ”¶æ•°æ®ï¼šæ—¥è¥æ”¶ã€åº—é“ºè¥æ”¶ã€äº§å“ç±»åˆ«è¥æ”¶
        - å®¢æˆ·æ•°æ®ï¼šå®¢æˆ·ç”»åƒã€å¿ è¯šåº¦ã€æ¶ˆè´¹è¡Œä¸º
        - ä¿ƒé”€æ•°æ®ï¼šä¿ƒé”€æ•ˆæœã€ROIåˆ†æ
        - å› æœåˆ†æï¼šä¿ƒé”€ã€å¤©æ°”ã€èŠ‚å‡æ—¥ç­‰å› ç´ çš„å› æœæ•ˆåº”
        - é¢„æµ‹æ•°æ®ï¼šæœªæ¥7-15å¤©çš„é”€å”®é¢„æµ‹
        """

        # æ„å›¾è¯†åˆ«æ¨¡æ¿
        self.intent_patterns = {
            "daily_report": ["æ—¥æŠ¥", "ä»Šå¤©", "ä»Šæ—¥", "æ•°æ®æ¦‚è§ˆ", "æ¦‚è§ˆ"],
            "sales_analysis": ["é”€å”®", "è¥æ”¶", "æ”¶å…¥", "é”€é‡", "ä¸šç»©"],
            "customer_analysis": ["å®¢æˆ·", "ç”¨æˆ·", "é¡¾å®¢", "ä¼šå‘˜", "å¿ è¯šåº¦"],
            "promotion_analysis": ["ä¿ƒé”€", "æ´»åŠ¨", "ä¼˜æƒ ", "æŠ˜æ‰£", "è¥é”€"],
            "causal_analysis": ["å› æœ", "å½±å“", "æ•ˆåº”", "åŸå› ", "ä¸ºä»€ä¹ˆ"],
            "forecast": ["é¢„æµ‹", "é¢„ä¼°", "æœªæ¥", "è¶‹åŠ¿", "å±•æœ›"],
            "comparison": ["å¯¹æ¯”", "æ¯”è¾ƒ", "ç¯æ¯”", "åŒæ¯”", "å·®å¼‚"],
            "detail": ["è¯¦ç»†", "å…·ä½“", "æ˜ç»†", "è¯¦æƒ…", "å±•å¼€"],
            "suggestion": ["å»ºè®®", "æ€ä¹ˆåŠ", "å¦‚ä½•", "ä¼˜åŒ–", "æ”¹è¿›"]
        }

    async def parse_query_intent(self, query: str) -> Dict[str, Any]:
        """è§£æç”¨æˆ·æŸ¥è¯¢æ„å›¾"""
        query_lower = query.lower()

        intent = {
            "query": query,
            "intent_type": "general",
            "entities": {},
            "needs_data": False,
            "time_range": self._extract_time_range(query),
            "metrics": self._extract_metrics(query)
        }

        # è¯†åˆ«ä¸»è¦æ„å›¾
        for intent_type, patterns in self.intent_patterns.items():
            if any(pattern in query_lower for pattern in patterns):
                intent["intent_type"] = intent_type
                intent["needs_data"] = True
                break

        # æå–å®ä½“
        intent["entities"] = self._extract_entities(query)

        # ä½¿ç”¨LLMå¢å¼ºæ„å›¾ç†è§£
        if intent["intent_type"] == "general":
            intent = await self._enhance_intent_with_llm(query, intent)

        return intent

    def _extract_time_range(self, query: str) -> Dict[str, Any]:
        """æå–æ—¶é—´èŒƒå›´"""
        time_range = {
            "type": "relative",
            "value": "today"
        }

        query_lower = query.lower()

        # ç›¸å¯¹æ—¶é—´
        if "ä»Šå¤©" in query or "ä»Šæ—¥" in query:
            time_range = {"type": "relative", "value": "today"}
        elif "æ˜¨å¤©" in query or "æ˜¨æ—¥" in query:
            time_range = {"type": "relative", "value": "yesterday"}
        elif "æœ¬å‘¨" in query or "è¿™å‘¨" in query:
            time_range = {"type": "relative", "value": "this_week"}
        elif "ä¸Šå‘¨" in query:
            time_range = {"type": "relative", "value": "last_week"}
        elif "æœ¬æœˆ" in query or "è¿™ä¸ªæœˆ" in query:
            time_range = {"type": "relative", "value": "this_month"}
        elif "ä¸Šæœˆ" in query or "ä¸Šä¸ªæœˆ" in query:
            time_range = {"type": "relative", "value": "last_month"}

        # å…·ä½“æ—¥æœŸï¼ˆç®€å•æ­£åˆ™åŒ¹é…ï¼‰
        date_pattern = r'(\d{4}[-/]\d{1,2}[-/]\d{1,2})'
        dates = re.findall(date_pattern, query)
        if dates:
            if len(dates) == 1:
                time_range = {"type": "absolute", "start": dates[0], "end": dates[0]}
            elif len(dates) >= 2:
                time_range = {"type": "absolute", "start": dates[0], "end": dates[1]}

        return time_range

    def _extract_metrics(self, query: str) -> List[str]:
        """æå–æŒ‡æ ‡å…³é”®è¯"""
        metrics = []
        query_lower = query.lower()

        metric_keywords = {
            "revenue": ["è¥æ”¶", "æ”¶å…¥", "é”€å”®é¢", "æµæ°´"],
            "orders": ["è®¢å•", "å•é‡", "äº¤æ˜“"],
            "customers": ["å®¢æˆ·", "ç”¨æˆ·", "é¡¾å®¢", "å®¢æµ"],
            "aov": ["å®¢å•ä»·", "å¹³å‡è®¢å•", "å•ä»·"],
            "conversion": ["è½¬åŒ–ç‡", "è½¬åŒ–", "æˆäº¤ç‡"],
            "loyalty": ["å¿ è¯šåº¦", "å¤è´­", "å›è´­", "ç•™å­˜"]
        }

        for metric, keywords in metric_keywords.items():
            if any(keyword in query_lower for keyword in keywords):
                metrics.append(metric)

        return metrics

    def _extract_entities(self, query: str) -> Dict[str, Any]:
        """æå–å®ä½“ï¼ˆåº—é“ºã€äº§å“ç­‰ï¼‰"""
        entities = {}

        # åº—é“ºæå–
        store_pattern = r'(CA|IL|AZ|TX)[-\w]*'
        stores = re.findall(store_pattern, query.upper())
        if stores:
            entities["stores"] = stores

        # äº§å“ç±»åˆ«æå–
        categories = ["å¥¶èŒ¶", "å’–å•¡", "æœèŒ¶", "å°é£Ÿ", "æ–°å“"]
        found_categories = [cat for cat in categories if cat in query]
        if found_categories:
            entities["categories"] = found_categories

        return entities

    async def _enhance_intent_with_llm(self, query: str, initial_intent: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨LLMå¢å¼ºæ„å›¾ç†è§£"""
        try:
            prompt = f"""
            åˆ†æç”¨æˆ·æŸ¥è¯¢æ„å›¾ï¼š
            æŸ¥è¯¢ï¼š{query}

            è¯·è¯†åˆ«ï¼š
            1. ä¸»è¦æ„å›¾ç±»å‹ï¼ˆdaily_report/sales_analysis/customer_analysis/promotion_analysis/causal_analysis/forecast/comparison/suggestionï¼‰
            2. æ˜¯å¦éœ€è¦æ•°æ®æ”¯æŒ
            3. å…³æ³¨çš„å…³é”®æŒ‡æ ‡

            è¿”å›JSONæ ¼å¼ã€‚
            """

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢æ„å›¾åˆ†æä¸“å®¶ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=200
            )

            # å°è¯•è§£æJSONå“åº”
            content = response.choices[0].message.content
            # ç®€å•å¤„ç†ï¼Œå®é™…å¯èƒ½éœ€è¦æ›´å¤æ‚çš„è§£æ
            if "sales_analysis" in content:
                initial_intent["intent_type"] = "sales_analysis"
                initial_intent["needs_data"] = True
            elif "forecast" in content:
                initial_intent["intent_type"] = "forecast"
                initial_intent["needs_data"] = True

        except Exception as e:
            print(f"LLM intent enhancement failed: {e}")

        return initial_intent

    async def generate_response(
            self,
            query: str,
            data: Optional[Dict[str, Any]] = None,
            context: Optional[List[Dict[str, Any]]] = None
    ) -> Dict[str, Any]:
        """ç”Ÿæˆå›å¤"""

        # æ„å»ºæ¶ˆæ¯å†å²
        messages = [
            {"role": "system", "content": self.system_prompt}
        ]

        # æ·»åŠ å†å²ä¸Šä¸‹æ–‡
        if context:
            for msg in context[-5:]:  # æœ€å¤š5æ¡å†å²
                if msg['role'] not in {"system", "assistant", "user", "function", "tool", "developer"}:
                    msg['role'] = "assistant"
                messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })

        # æ„å»ºå½“å‰æŸ¥è¯¢çš„ä¸Šä¸‹æ–‡
        current_context = f"ç”¨æˆ·æŸ¥è¯¢ï¼š{query}\n"

        if data:
            current_context += "\nç›¸å…³æ•°æ®ï¼š\n"
            current_context += self._format_data_for_llm(data)

        messages.append({"role": "user", "content": current_context})

        try:
            # è°ƒç”¨LLM
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=1000
            )

            bot_message = response.choices[0].message.content

            # æ„å»ºå“åº”
            result = {
                "message": bot_message,
                "data": None
            }

            # å¦‚æœæœ‰æ•°æ®ï¼Œæ ¼å¼åŒ–ä¸ºå‰ç«¯å¯ç”¨çš„æ ¼å¼
            if data:
                result["data"] = self._format_data_for_frontend(data)

            return result

        except Exception as e:
            print(f"LLM generation failed: {e}")
            return {
                "message": "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ã€‚è¯·ç¨åå†è¯•ã€‚",
                "data": None
            }

    def _format_data_for_llm(self, data: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æ•°æ®ä¾›LLMç†è§£"""
        formatted = []

        if "metrics" in data:
            formatted.append("ğŸ“Š å…³é”®æŒ‡æ ‡ï¼š")
            for key, value in data["metrics"].items():
                formatted.append(f"- {key}: {value}")

        if "analysis" in data:
            formatted.append("\nğŸ¯ åˆ†æç»“æœï¼š")
            for key, value in data["analysis"].items():
                if isinstance(value, dict) and "ate" in value:
                    formatted.append(f"- {key}: æ•ˆåº”å€¼={value['ate']:.2f}, æ˜¾è‘—æ€§={value.get('significant', False)}")

        if "forecast" in data:
            formatted.append("\nğŸ“ˆ é¢„æµ‹æ•°æ®ï¼š")
            forecast = data["forecast"]
            formatted.append(
                f"- æœªæ¥{forecast.get('forecast_days', 0)}å¤©æ€»é¢„æµ‹: ${forecast.get('total_forecast', 0):,.0f}"
            )
            formatted.append(
                f"- æ—¥å‡é¢„æµ‹: ${forecast.get('avg_daily_forecast', 0):,.0f}"
            )
            method = data.get("method")
            if method:
                formatted.append(f"- é¢„æµ‹æ–¹æ³•: {method}")

        return "\n".join(formatted)

    def _format_data_for_frontend(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–æ•°æ®ä¾›å‰ç«¯å±•ç¤º"""
        formatted = {
            "type": "data_display",
            "content": {}
        }

        # æ·»åŠ æ‰€æœ‰å¯ç”¨å†…å®¹
        if "metrics" in data:
            formatted["content"]["metrics"] = data["metrics"]

        if "forecast" in data:
            formatted["content"]["chart"] = data["forecast"]["chart_data"]
            formatted["display_type"] = "chart"

        if "chart_data" in data:
            formatted["content"]["chart"] = data["chart_data"]

        if "table_data" in data:
            formatted["content"]["table"] = data["table_data"]

        if "analysis" in data:
            formatted["content"]["analysis"] = data["analysis"]

        # æŒ‰ä¼˜å…ˆçº§ç¡®å®šå±•ç¤ºç±»å‹ï¼Œç¡®ä¿ç¨³å®š
        type_priority = ["analysis", "chart_data", "table_data", "metrics"]
        type_map = {
            "analysis": lambda: "causal_analysis" if "causal" in str(data.get("analysis_type", "")) else "analysis",
            "chart_data": lambda: "chart",
            "table_data": lambda: "table",
            "metrics": lambda: "metrics_cards",
        }

        for key in type_priority:
            if key in data:
                formatted["display_type"] = type_map[key]()
                break

        return formatted

    async def generate_suggestions(self, analysis_results: Dict[str, Any]) -> List[str]:
        """åŸºäºåˆ†æç»“æœç”Ÿæˆå»ºè®®"""
        suggestions = []

        prompt = f"""
        åŸºäºä»¥ä¸‹åˆ†æç»“æœï¼Œç”Ÿæˆ3-5æ¡å…·ä½“å¯è¡Œçš„ä¸šåŠ¡å»ºè®®ï¼š
        {json.dumps(analysis_results, ensure_ascii=False, indent=2)}

        è¦æ±‚ï¼š
        1. æ¯æ¡å»ºè®®è¦å…·ä½“å¯æ‰§è¡Œ
        2. åŒ…å«é¢„æœŸæ•ˆæœ
        3. æŒ‰ä¼˜å…ˆçº§æ’åº
        """

        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸šåŠ¡ç­–ç•¥ä¸“å®¶ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )

            content = response.choices[0].message.content
            # è§£æå»ºè®®ï¼ˆç®€å•æŒ‰è¡Œåˆ†å‰²ï¼‰
            suggestions = [line.strip() for line in content.split('\n') if line.strip() and not line.startswith('#')]

        except Exception as e:
            print(f"Generate suggestions failed: {e}")
            suggestions = ["å»ºè®®1: ä¼˜åŒ–ä¿ƒé”€ç­–ç•¥", "å»ºè®®2: å…³æ³¨å®¢æˆ·ç•™å­˜", "å»ºè®®3: æå‡è¿è¥æ•ˆç‡"]

        return suggestions[:5]  # æœ€å¤šè¿”å›5æ¡